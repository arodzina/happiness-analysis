---
title: "Modelowanie dobrostanu subiektywnego na podstawie danych World Happiness Report"
author: "Twoje Imię i nazwisko"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(car)
library(corrplot)
library(lmtest)
library(sandwich)
library(psych)
library(ggplot2)
```

## 1. Wstęp

Celem analizy jest zbudowanie modelu regresji liniowej, który przewiduje poziom zadowolenia z życia (Life Ladder) na podstawie zmiennych społeczno-ekonomicznych zawartych w raporcie World Happiness Report.

## 2. Wczytanie i przygotowanie danych

```{r load-data}
data <- read.csv("World Happiness Report 2024.csv", sep = ";")
data_clean <- na.omit(data)
glimpse(data_clean)
```

## 3. Statystyki opisowe i korelacje

```{r desc-stats}
describe(data_clean %>% select(-Country.name, -year))
corrplot(cor(data_clean %>% select_if(is.numeric)), method = "circle", type = "upper")
```

## 3a. Opis zmiennych 

Country name: The country for which the data is reported.
Year: The year in which the data was collected.
Life Ladder: A measure of subjective well-being or life satisfaction on a scale where higher values generally indicate greater happiness.
Log GDP per capita: The logarithm of GDP per capita, reflecting economic prosperity and its impact on happiness.
Social support: A metric indicating the level of perceived social support or network available to individuals.
Healthy life expectancy at birth: The number of years a person is expected to live in good health from birth.
Freedom to make life choices: A measure of how free individuals feel in making life decisions.
Generosity: A metric reflecting the level of generosity or charitable giving in a country.
Perceptions of corruption: A measure of how corrupt the government is perceived to be, influencing trust and satisfaction.
Positive affect: The level of positive emotions such as joy and contentment experienced by individuals.
Negative affect: The level of negative emotions such as sadness and anxiety experienced by individuals.

## 4. Podział na zbiór treningowy i testowy

```{r split-data}
set.seed(123)

train <- data_clean %>% slice_sample(prop = 0.9) 
test <- anti_join(data_clean, train)
```

```{r}
data_cleaned = data_clean %>% select(-Country.name, -year) 
# metoda Hellwiga

hellwig<-function(data) { #zał. y jest w pierwszej kolumnie
cor_matrix <- cor(data)
R0 <- cor_matrix[1, -1] #korelacja y z wszystkimi zmiennymi objaśniającymi
R <- cor_matrix[-1,-1] #korelacjazmiennych objaśniających między sobą


L <- 2^8-1

comb <- expand.grid(rep(list(c(T, F)), 8))

# pętla od 1 do L
#szukamy kombinacji która ma największa H

best_H <- 0 #najlepszy współczynnik H
best_k <- NULL #najlepszy zestaw zmiennych

R <- abs(R)

for (i in 1:L) {
  k <- c(1:8)[unlist(comb[i,])] #wiesz TRUE FALSE z naszego comb (które zmienne w tym wypadku bierzemy a które nie)
  H <- 0 #wyżej = z wektora logicznego wybierz tylko te wartości, które są TRUE
  
  for (j in k) {
    H = H + R0[j]^2/sum(R[j,k])
  }
  
  if (H > best_H) {
    best_H <- H
    best_k <- k
  }
}

best_H
best_k
return(colnames(data)[best_k + 1])}
hellwig(data=data_cleaned)
```
Metoda Hellwiga pokazała, że Life Ladder w największym stopniu zależy od PKB na osobę, wsparcia społecznego, przewidywanej długości życia, poziomu korupcji w kraju oraz pozytywnych emocji.

## 5. Budowa modelu regresji liniowej

```{r fit-model}
model <- lm(`Life.Ladder` ~ `Log.GDP.per.capita` + `Social.support` +
              `Healthy.life.expectancy.at.birth` + `Freedom.to.make.life.choices` +
              Generosity + `Perceptions.of.corruption` + `Positive.affect` + `Negative.affect`,
              data = train)
summary(model)

model2 <- lm(`Life.Ladder` ~ `Log.GDP.per.capita` + `Social.support` +
              `Healthy.life.expectancy.at.birth` +
               `Perceptions.of.corruption` + `Positive.affect`,
              data = train)
summary(model2)
plot(model2)
```
Pierwszy model sprawdza istatność statystyczną wszystkich zmiennych i ich wpływ na Life Ladder. Okazuje się, że głównie Negative affect słabo objaśnia poziom satysfakcji życiowej. Z tego względu zrezygnujemy z tej zmiennej w drugim modelu. Dodatkowo nie użyjemy również Generosity i Freedom to make life choices, ponieważ nie zostały one wybrane metodą Hellwiga.

## 6. Diagnostyka modelu

```{r diagnostics}
# Współliniowość
vif(model2)
```
Badamy tutaj, czy zmienne objaśniające są ze sobą silnie skorelowane. Wspólniniowość występuje raczej niska lub umiarkowana. Dla poziomu PKB jest lekko wyższa, ale nie przekracza wartości 5, która stanowiłaby juz problem. Z tego względu nie trzeba korygować postaci modelu.

```{r diagnostics}
res <- model2$residuals
hist(res)
# Normalność reszt
shapiro.test(res)
qqnorm(res); qqline(res)
```
Sprawdzamy reszty modelu. Histogram pokazuje, że ich rozkład przypomina normalny, jest symetryczny względem zera i nie wykazuje wartości odstających, co dobrze świadczy. Test normalności Shapiro-Wilka wskazuje jednak, że powinniśmy odrzucić hipotezę zerową o normalności rozkładu. Z drugiej strony wykres kwantyl-kwantyl wygląda całkiem przyzwoicie. Większość punktów leży blisko linii prostej - oznacza to, że reszty są w przybliżeniu normalne w środku rozkładu.Odchylenia na końcach (lewa i prawa strona) — wskazują na lekkie odstępstwa w ogonach. Nie ma dramatycznych odchyleń, żadnych ekstremalnych punktów bardzo daleko od linii. Nawet gdy reszty nie mają rozkładu idealnie normalnego, to nie jest to problem, jeśli mamy dużą próbę i wykresy pozwalają na stwierdzenie podobieństwa do rozkładu normalnego. Dodatkowo naszym celem jest przecież prognoza, więc taki rozkład reszt modelu jest w porządku.

```{r diagnostics}
# Heteroskedastyczność
bptest(model2)
```
Wynik testu Breuscha-Pagana informuje o tym, czy w modelu występuje heteroskedastyczność, czyli zmienność wariancji reszt w zależności od wartości zmiennych objaśniających — co łamie jedno z podstawowych założeń regresji liniowej. Test ten pokazał, że w naszym modelu występuje heteroskedastyczność. Przy prognozowaniu nie jest to bardzo istotnym problemem.

```{r diagnostics}
# Autokorelacja
dwtest(model2)
```
Wynik testu Durbin-Watsona ocenia, czy w resztach modelu występuje autokorelacja — czyli zależność reszt między sobą. DW = 1,89 oznacza istotną statystycznie autokorelację reszt. 

## 7. Prognoza i ocena modelu

```{r prediction}
pred <- predict(model2, newdata = test)
mae <- mean(abs(pred - test$`Life.Ladder`))
rmse <- sqrt(mean((pred - test$`Life.Ladder`)^2))
mae
rmse
```
MAE (Mean Absolute Error) = 0.4267
→ Średni błąd bezwzględny prognozy: model myli się średnio o 0.43 jednostki w przewidywaniu poziomu szczęścia (Life.Ladder).

RMSE (Root Mean Square Error) = 0.5551
→ Błąd średniokwadratowy: uwzględnia większe kary dla dużych błędów.
Zarówno MAE < 0.5, jak i RMSE < 0.6, co przy skali Life.Ladder (zwykle 0–10) oznacza, że model radzi sobie dobrze z predykcją.

Różnica między RMSE a MAE jest umiarkowana, co oznacza, że nie ma dużych ekstremalnych błędów.

## 8. Wykresy wyników

```{r plots}
# Predykcja vs rzeczywiste
pred_df <- data.frame(pred, actual = test$`Life.Ladder`)
ggplot(pred_df, aes(x = actual, y = pred)) +
  geom_point() +
  geom_abline(color = "red", linetype = "dashed") +
  labs(title = "Predykcja vs Rzeczywiste wartości", x = "Rzeczywiste", y = "Predykcja")

# Wykres reszt
ggplot(data.frame(resid = residuals(model2), fitted = fitted(model2)),
       aes(x = fitted, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  labs(title = "Reszty vs dopasowane wartości", x = "Dopasowane", y = "Reszty")
```
```{r}
model_year <- lm(Life.Ladder ~ Log.GDP.per.capita + Social.support +
                   Healthy.life.expectancy.at.birth + Perceptions.of.corruption +
                   Positive.affect + factor(year), data = train)
summary(model_year)
anova(model2, model_year)
AIC(model2, model_year)
vif(model_year)


pred <- predict(model_year, newdata = test)
mae <- mean(abs(pred - test$`Life.Ladder`))
rmse <- sqrt(mean((pred - test$`Life.Ladder`)^2))
mae
rmse
```
Próba stworzenia modelu uwzględniającego czas. Żaden rok nie jest istotny statystycznie — wszystkie mają p-value znacznie powyżej 0.05. To oznacza, że po uwzględnieniu innych zmiennych (gospodarka, zdrowie itd.), sam rok nie wnosi istotnej zmiany w poziomie szczęścia. Możliwe, że trendy czasowe są już "wychwycone" przez inne zmienne. Anova daje nam jednak informację, że RSS (Residual Sum of Squares) spadło z 545.49 do 532.57, co oznacza, że model 2 lepiej dopasowuje się do danych. Test F sprawdza, czy ta poprawa jest istotna statystycznie. p-value = 0.0004378 → oznacza, że poprawa dopasowania jest istotna na poziomie istotności 0.001. Choć żaden pojedynczy rok w modelu nie był istotny, to rok jako grupa zmiennych kategorycznych wnosi statystycznie istotną informację. Dodanie factor(year) poprawia dopasowanie modelu. Rok wnosi coś istotnego statystycznie, bo nawet niewielka poprawa dopasowania (spadek RSS) przy tak dużej liczbie danych oznacza, że efekt roku jest realny, a nie losowy.

AIC (Akaike Information Criterion) jest również niższy dla model_year. Mimo że model_year ma więcej parametrów (25 vs 7), to i tak wyraźnie lepiej dopasowuje się do danych po uwzględnieniu złożoności.
To kolejny dowód (po ANOVA), że dodanie factor(year) ma sens i jest uzasadnione statystycznie.

Mimo że model_year ma lepsze dopasowanie do danych treningowych (niższy AIC, lepszy ANOVA), jego trafność predykcji na danych testowych jest minimalnie gorsza.
Różnice są jednak bardzo niewielkie i mogą być przypadkowe (w granicach błędu).
Dodanie factor(year) poprawia dopasowanie i ujawnia drobny efekt lat, ale nie poprawia (ani nie pogarsza znacząco) trafności prognozy.

Możemy potraktować tę część projektu jako swego rodzaju eksperyment.

## 9. Podsumowanie (do zmiany)

Model wykazał, że największy wpływ na poziom zadowolenia z życia mają m.in. `Log GDP per capita`, `Social support` oraz `Freedom to make life choices`. Diagnoza reszt wskazuje na pewne odstępstwa od założeń klasycznego modelu liniowego, ale model osiąga stosunkowo niskie błędy (MAE, RMSE), co świadczy o dobrej jakości dopasowania.

W kolejnym kroku możliwa jest rozbudowa analizy o modele panelowe z efektami stałymi lub losowymi, co może poprawić ujęcie efektów krajowych i czasowych.
