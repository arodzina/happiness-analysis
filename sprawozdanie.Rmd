---
title: "Modelowanie dobrostanu subiektywnego na podstawie danych World Happiness Report"
author: "Twoje Imię i nazwisko"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(car)
library(corrplot)
library(sandwich)
library(psych)
library(moments)
library(ggplot2)
library(strucchange)
library(lmtest)
library(countrycode)
```

## 1. Wstęp

Celem analizy jest zbudowanie modelu regresji liniowej, który przewiduje poziom zadowolenia z życia (Life Ladder) na podstawie zmiennych społeczno-ekonomicznych zawartych w raporcie World Happiness Report.

## 2. Wczytanie i przygotowanie danych

```{r load-data}
data <- read.csv("World Happiness Report 2024.csv", sep = ";")
data_clean <- na.omit(data)
glimpse(data_clean)
```

## 3. Statystyki opisowe i korelacje

```{r desc-stats}
describe(data_clean %>% select(-Country.name, -year))
corrplot(cor(data_clean %>% select_if(is.numeric)), method = "circle", type = "upper")
```

## 3a. Opis zmiennych 

Country name: The country for which the data is reported.
Year: The year in which the data was collected.
Life Ladder: A measure of subjective well-being or life satisfaction on a scale where higher values generally indicate greater happiness.
Log GDP per capita: The logarithm of GDP per capita, reflecting economic prosperity and its impact on happiness.
Social support: A metric indicating the level of perceived social support or network available to individuals.
Healthy life expectancy at birth: The number of years a person is expected to live in good health from birth.
Freedom to make life choices: A measure of how free individuals feel in making life decisions.
Generosity: A metric reflecting the level of generosity or charitable giving in a country.
Perceptions of corruption: A measure of how corrupt the government is perceived to be, influencing trust and satisfaction.
Positive affect: The level of positive emotions such as joy and contentment experienced by individuals.
Negative affect: The level of negative emotions such as sadness and anxiety experienced by individuals.

## 4. Podział na zbiór treningowy i testowy

```{r split-data}
set.seed(123)

train <- data_clean %>% slice_sample(prop = 0.9) 
test <- anti_join(data_clean, train)
```

```{r}
data_cleaned = data_clean %>% select(-Country.name, -year) 
# metoda Hellwiga

hellwig<-function(data,n) { #zał. y jest w pierwszej kolumnie
cor_matrix <- cor(data)
R0 <- cor_matrix[1, -1] #korelacja y z wszystkimi zmiennymi objaśniającymi
R <- cor_matrix[-1,-1] #korelacjazmiennych objaśniających między sobą


L <- 2^n-1

comb <- expand.grid(rep(list(c(T, F)), n))

# pętla od 1 do L
#szukamy kombinacji która ma największa H

best_H <- 0 #najlepszy współczynnik H
best_k <- NULL #najlepszy zestaw zmiennych

R <- abs(R)

for (i in 1:L) {
  k <- c(1:n)[unlist(comb[i,])] #wiesz TRUE FALSE z naszego comb (które zmienne w tym wypadku bierzemy a które nie)
  H <- 0 #wyżej = z wektora logicznego wybierz tylko te wartości, które są TRUE
  
  for (j in k) {
    H = H + R0[j]^2/sum(R[j,k])
  }
  
  if (H > best_H) {
    best_H <- H
    best_k <- k
  }
}

best_H
best_k
return(colnames(data)[best_k + 1])}
hellwig(data=data_cleaned, n=8)
```
Metoda Hellwiga pokazała, że Life Ladder w największym stopniu zależy od PKB na osobę, wsparcia społecznego, przewidywanej długości życia, poziomu korupcji w kraju oraz pozytywnych emocji.

## 5. Budowa modeli regresji liniowej

```{r fit-model}
model <- lm(`Life.Ladder` ~ `Log.GDP.per.capita` + `Social.support` +
              `Healthy.life.expectancy.at.birth` + `Freedom.to.make.life.choices` +
              Generosity + `Perceptions.of.corruption` + `Positive.affect` + `Negative.affect`,
              data = train)
summary(model)
resettest(model)

model2 <- lm(`Life.Ladder` ~ `Log.GDP.per.capita` + `Social.support` +
              `Healthy.life.expectancy.at.birth` +
               `Perceptions.of.corruption` + `Positive.affect`,
              data = train)
summary(model2)
plot(model2)
```
Pierwszy model sprawdza istatność statystyczną wszystkich zmiennych i ich wpływ na Life Ladder. Okazuje się, że głównie Negative affect słabo objaśnia poziom satysfakcji życiowej. Z tego względu zrezygnujemy z tej zmiennej w drugim modelu. Dodatkowo nie użyjemy również Generosity i Freedom to make life choices, ponieważ nie zostały one wybrane metodą Hellwiga.

## 6. Diagnostyka modelu

```{r diagnostics}
# Współliniowość
vif(model2)
```
Badamy tutaj, czy zmienne objaśniające są ze sobą silnie skorelowane. Wspólniniowość występuje raczej niska lub umiarkowana. Dla poziomu PKB jest lekko wyższa, ale nie przekracza wartości 5, która stanowiłaby juz problem. Z tego względu nie trzeba korygować postaci modelu.

```{r diagnostics}
res <- model2$residuals
hist(res)
skewness(res)
kurtosis(res)
# Normalność reszt
shapiro.test(res)
qqnorm(res); qqline(res)
```
Sprawdzamy reszty modelu. Histogram pokazuje, że ich rozkład przypomina normalny, jest symetryczny względem zera i nie wykazuje wartości odstających, co dobrze świadczy. Test normalności Shapiro-Wilka wskazuje jednak, że powinniśmy odrzucić hipotezę zerową o normalności rozkładu. Z drugiej strony wykres kwantyl-kwantyl wygląda całkiem przyzwoicie. Większość punktów leży blisko linii prostej - oznacza to, że reszty są w przybliżeniu normalne w środku rozkładu.Odchylenia na końcach (lewa i prawa strona) — wskazują na lekkie odstępstwa w ogonach. Nie ma dramatycznych odchyleń, żadnych ekstremalnych punktów bardzo daleko od linii. Nawet gdy reszty nie mają rozkładu idealnie normalnego, to nie jest to problem, jeśli mamy dużą próbę i wykresy pozwalają na stwierdzenie podobieństwa do rozkładu normalnego. Dodatkowo naszym celem jest przecież prognoza, więc taki rozkład reszt modelu jest w porządku.
Skośność bliska zeru. Tylko lekko dłuższy ogon po lewej stronie. Kurtoza niewiele ponad trzy oznacza wyszczuplony, wysoki rozkład - dużo wartości bliskich średniej, nieco cięższe ogony niż w rozkładzie normalnym.

```{r diagnostics}
# Heteroskedastyczność
bptest(model2)

#tu chyba badamy heteroskedastyczność jeśli chodzi o  PKB ale nie wiem jakie wnioski napisać

gqtest(model2, point = 0.5, order.by = ~Log.GDP.per.capita, data = train)

plot(train$Log.GDP.per.capita, train$Life.Ladder,
     xlab = "Log GDP per Capita", ylab = "Life Ladder",
     main = "Zależność: PKB a Szczęście", col = "steelblue", pch = 16)
abline(lm(Life.Ladder ~ Log.GDP.per.capita, data = train), col = "red", lwd = 2)

res <- residuals(lm(Life.Ladder ~ Log.GDP.per.capita, data = train))
plot(train$Log.GDP.per.capita, res,
     xlab = "Log GDP per Capita", ylab = "Reszty",
     main = "Reszty względem Log GDP", pch = 16, col = "grey")
abline(h = 0, col = "red")


```
Wynik testu Breuscha-Pagana informuje o tym, czy w modelu występuje heteroskedastyczność, czyli zmienność wariancji reszt w zależności od wartości zmiennych objaśniających — co łamie jedno z podstawowych założeń regresji liniowej. Test ten pokazał, że w naszym modelu występuje heteroskedastyczność. Przy prognozowaniu nie jest to bardzo istotnym problemem.

```{r diagnostics}
# Autokorelacja
dwtest(model2)

#stabilność modelu
#Test Ramseya
resettest(model2)
sctest(model2)
```
Wynik testu Durbin-Watsona ocenia, czy w resztach modelu występuje autokorelacja — czyli zależność reszt między sobą. DW = 1,89 oznacza istotną statystycznie autokorelację reszt.

Wynik drugi pochodzi z RESET testu (Ramsey Regression Equation Specification Error Test), który sprawdza, czy w modelu regresji liniowej brakuje ważnych zmiennych lub występuje nieliniowość nieujęta w modelu. Odrzucamy H0 na korzyść hipotezy alternatywna (H₁): model jest źle wyspecyfikowany — być może brakuje jakichś istotnych zmiennych, relacje między zmiennymi są nieliniowe, ale model zakłada liniowość.

Wynik testu M-fluctuation dotyczy stabilności parametrów modelu regresji w czasie lub w innej kolejności danych (np. wg roku, kraju itp.). Model model2 jest parametrycznie stabilny — nie widać, by jego współczynniki zmieniały się istotnie w czasie lub między grupami danych.
To dobry znak, szczególnie przy danych wieloletnich, bo sugeruje, że relacje między zmiennymi są trwałe i spójne.

## 7. Prognoza i ocena modelu

```{r prediction}
pred <- predict(model2, newdata = test, interval="p")
mae <- mean(abs(pred - test$`Life.Ladder`))
rmse <- sqrt(mean((pred - test$`Life.Ladder`)^2))
mae
rmse

df <- data.frame(
  Actual = test$Life.Ladder,
  Prediction = pred[, "fit"],
  Lower = pred[, "lwr"],
  Upper = pred[, "upr"]
)

df %>%
  mutate(hit = if_else(Actual >= Lower & Actual <= Upper, TRUE, FALSE)) %>%
  summarise(hitrate = mean(hit))
```
MAE (Mean Absolute Error) = 0.4267
→ Średni błąd bezwzględny prognozy: model myli się średnio o 0.43 jednostki w przewidywaniu poziomu szczęścia (Life.Ladder).

RMSE (Root Mean Square Error) = 0.5551
→ Błąd średniokwadratowy: uwzględnia większe kary dla dużych błędów.
Zarówno MAE < 0.5, jak i RMSE < 0.6, co przy skali Life.Ladder (zwykle 0–10) oznacza, że model radzi sobie dobrze z predykcją.

Różnica między RMSE a MAE jest umiarkowana, co oznacza, że nie ma dużych ekstremalnych błędów.

93% predykcji mieści się w przedziałach ufności. To naprawdę dobry wynik przy poziomie istotności 95%.

## 8. Wykresy wyników

```{r plots}
# Predykcja vs rzeczywiste

plot(test$Life.Ladder, pred[,"fit"], 
     xlab = "Rzeczywiste wartości szczęścia", 
     ylab = "Przewidywane wartości szczęścia", 
     main = "Porównanie rzeczywistych vs przewidywanych wartości szczęścia",
     col = "blue", pch = 16)
abline(0, 1, col = "red", lwd = 2)

# Wykres reszt
ggplot(data.frame(resid = residuals(model2), fitted = fitted(model2)),
       aes(x = fitted, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  labs(title = "Reszty vs dopasowane wartości", x = "Dopasowane", y = "Reszty")
```
```{r}
model_year <- lm(Life.Ladder ~ Log.GDP.per.capita + Social.support +
                   Healthy.life.expectancy.at.birth + Perceptions.of.corruption +
                   Positive.affect + factor(year), data = train)
summary(model_year)
anova(model2, model_year)
AIC(model2, model_year)
vif(model_year)


pred <- predict(model_year, newdata = test)
mae <- mean(abs(pred - test$`Life.Ladder`))
rmse <- sqrt(mean((pred - test$`Life.Ladder`)^2))
mae
rmse
error <- test$Life.Ladder - pred
MAE <- mean(abs(error))
MAPE <- mean(abs(error / test$Life.Ladder))*100
RMSE <- sqrt(mean(error^2))
cat("MAE:", MAE, "\nMAPE:", MAPE, "\nRMSE:", RMSE, "\n")
resettest(model_year)
```
Próba stworzenia modelu uwzględniającego czas. Żaden rok nie jest istotny statystycznie — wszystkie mają p-value znacznie powyżej 0.05. To oznacza, że po uwzględnieniu innych zmiennych (gospodarka, zdrowie itd.), sam rok nie wnosi istotnej zmiany w poziomie szczęścia. Możliwe, że trendy czasowe są już "wychwycone" przez inne zmienne. Anova daje nam jednak informację, że RSS (Residual Sum of Squares) spadło z 545.49 do 532.57, co oznacza, że model 2 lepiej dopasowuje się do danych. Test F sprawdza, czy ta poprawa jest istotna statystycznie. p-value = 0.0004378 → oznacza, że poprawa dopasowania jest istotna na poziomie istotności 0.001. Choć żaden pojedynczy rok w modelu nie był istotny, to rok jako grupa zmiennych kategorycznych wnosi statystycznie istotną informację. Dodanie factor(year) poprawia dopasowanie modelu. Rok wnosi coś istotnego statystycznie, bo nawet niewielka poprawa dopasowania (spadek RSS) przy tak dużej liczbie danych oznacza, że efekt roku jest realny, a nie losowy.

AIC (Akaike Information Criterion) jest również niższy dla model_year. Mimo że model_year ma więcej parametrów (25 vs 7), to i tak wyraźnie lepiej dopasowuje się do danych po uwzględnieniu złożoności.
To kolejny dowód (po ANOVA), że dodanie factor(year) ma sens i jest uzasadnione statystycznie.

Mimo że model_year ma lepsze dopasowanie do danych treningowych (niższy AIC, lepszy ANOVA), jego trafność predykcji na danych testowych jest minimalnie gorsza.
Różnice są jednak bardzo niewielkie i mogą być przypadkowe (w granicach błędu).
Dodanie factor(year) poprawia dopasowanie i ujawnia drobny efekt lat, ale nie poprawia (ani nie pogarsza znacząco) trafności prognozy.

Możemy potraktować tę część projektu jako swego rodzaju eksperyment.

## Podział świata na regiony
```{r}
data_2<-data_clean
data_2$Region <- countrycode(sourcevar = data_clean$Country.name,
                           origin = "country.name",
                           destination = "region")
data_2$RegionCode <- as.numeric(factor(data_2$Region))
levels(factor(data_2$Region))


ggplot(data_2, aes(x = factor(Region), y = Life.Ladder)) +
  geom_boxplot(fill = "skyblue", alpha = 0.7, outlier.color = "red") +
  stat_summary(fun = mean, geom = "point", shape = 20, size = 3, color = "darkblue", 
               position = position_dodge(width = 0.75)) +
  labs(
    title = "Rozkład szczęścia (Life Ladder) w regionach",
    x = "Region",
    y = "Life Ladder"
  ) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


data_2 %>%
  group_by(year, Region) %>%
  summarise(mean_life = mean(Life.Ladder, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = mean_life, color = factor(Region))) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  labs(
    title = "Średni poziom szczęścia w regionach na przestrzeni lat",
    x = "Rok",
    y = "Średni Life Ladder",
    color = "Region"
  ) +
  theme_minimal(base_size = 14)

anova_region <- aov(Life.Ladder ~ factor(Region), data = data_2)
summary(anova_region)

data_2cleaned<-data_2 %>% select(-year, -Country.name, -Region)
hellwig(data_2cleaned,9)

train1 <- data_2 %>% slice_sample(prop = 0.9) 
test1 <- anti_join(data_2, train)

model3 <- lm(`Life.Ladder` ~  `Social.support` +
              `Healthy.life.expectancy.at.birth`
              + `Perceptions.of.corruption` + `Positive.affect` + factor(RegionCode),
              data = train1)
summary(model3)
anova(model3, model2)
AIC(model3, model2)
vif(model3)


pred1 <- predict(model3, newdata = test1, interval="prediction")
df <- data.frame(
  Actual = test1$Life.Ladder,
  Prediction = pred1[, "fit"],
  Lower = pred1[, "lwr"],
  Upper = pred1[, "upr"]
)

df %>%
  mutate(hit = if_else(Actual >= Lower & Actual <= Upper, TRUE, FALSE)) %>%
  summarise(hitrate = mean(hit))
# Autokorelacja
dwtest(model3)

#stabilność modelu
#Test Ramseya
resettest(model3)
sctest(model3)
```
ANOVA: p-value < 2e-16 → bardzo silne podstawy do odrzucenia H₀.

To oznacza, że region ma istotny wpływ na poziom szczęścia — przynależność regionalna wyjaśnia dużą część zmienności. Suma kwadratów dla regionu (1205) jest znacznie większa niż dla reszt (1505), co znaczy, że duża część wariancji Life Ladder jest związana z regionem. Regiony bardzo istotnie różnią się między sobą pod względem poziomu szczęścia.
To idealne uzasadnienie, żeby uwzględniać region w modelach predykcyjnych lub interpretacyjnych.

## 9. Podsumowanie (do zmiany)

Model wykazał, że największy wpływ na poziom zadowolenia z życia mają m.in. `Log GDP per capita`, `Social support` oraz `Freedom to make life choices`. Diagnoza reszt wskazuje na pewne odstępstwa od założeń klasycznego modelu liniowego, ale model osiąga stosunkowo niskie błędy (MAE, RMSE), co świadczy o dobrej jakości dopasowania.

W kolejnym kroku możliwa jest rozbudowa analizy o modele panelowe z efektami stałymi lub losowymi, co może poprawić ujęcie efektów krajowych i czasowych.
